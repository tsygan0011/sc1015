# Cardiovascular Disease

# About

This is a Mini-Project for SC1015 (Introduction to Data Science and Artificial Intelligence) which focuses on cardiovascular disease. 

CVDs are a big deal both globally and locally. They are the leading cause of death globally, taking an estimated 17.9 millions lives annually, representing 32% of deaths worldwide. In 2020, CVDs accounted for 31.5% of all deaths and 7.1% of the total hospitalisation in Singapore.

Detecting CVDs require a wide range of diagnostic tests performed by specialists. It is also important to check for CVDs regularly. Considering these factors, many individuals are priced out of the opportunity to test and check for CVDs, resulting in many preventable deaths.

# Contributors

@Enoch - Data cleaning, Exploratory analysis

@YuHsuan - Logistic Regression

@Xavier - Random Forest, Gaussian Naive Bayes, XGBoost


# Problem Definition

How can we help individuals determine their CVD risk level easily and cheaply.

Which model would be the best to predict it?

# Models Used

Logistic Regression

Gaussian Naive Bayes algorithm 

RandomForest with gradient boosting(XGBoost algorithm)

# Conclusion

We identified four features to use for our model: Age, Cholesterol, Blood Pressure and BMI

Our model comes in at roughly 69.87% accuracy. Considering that our model aims to be a cheap and efficient preliminary check to identify high CVD risk patients, this is acceptable.




# What did we learn from this project?

Gaussian Naive Bayes from sklearn

Logistic Regression from sklearn

Collaborating using GitHub

Usage of gradient boosting(xgboost)

# Note

Installation of xgboost module guide

https://xgboost.readthedocs.io/en/stable/install.html


# References

https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset

https://blog.quantinsti.com/creating-heatmap-using-python-seaborn/

https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/

https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/

https://iq.opengenus.org/gaussian-naive-bayes/

[https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html](https://scikit-learn.org/stable/modules/tree.html)

https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html

https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html

https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html

https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html

https://towardsdatascience.com/getting-started-with-xgboost-in-scikit-learn-f69f5f470a97

